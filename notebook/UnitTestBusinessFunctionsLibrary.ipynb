{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%configure -f\r\n",
        "{ \"conf\": {\"spark.jars.packages\": \"org.scalatest:scalatest_2.12:3.2.14\"}}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "44",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-25T17:21:34.5345873Z",
              "session_start_time": "2023-01-25T17:21:34.8533769Z",
              "execution_start_time": "2023-01-25T17:22:23.9682251Z",
              "execution_finish_time": "2023-01-25T17:22:23.9685727Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(, 44, -1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 70,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%run BusinessFunctionsLibrary"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "44",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-25T17:21:34.6388006Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-25T17:22:34.9699805Z",
              "execution_finish_time": "2023-01-25T17:22:34.970291Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(, 44, -1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import org.apache.spark.sql.expressions.UserDefinedFunction\nimport org.apache.spark.sql.functions.udf\ndefined object UdfFunction\n"
          ]
        }
      ],
      "execution_count": 71,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import org.apache.spark.sql.{DataFrame, SparkSession}\r\n",
        "import org.scalatest._\r\n",
        "import flatspec._\r\n",
        "import matchers._\r\n",
        "\r\n",
        "/**\r\n",
        " * UDF Related Test cases from [[BusinessFunctionsLibrary]]\r\n",
        " */\r\n",
        "class UdfFunctionSpec extends  AnyFlatSpec with should.Matchers {\r\n",
        "\r\n",
        "  val sql: String => DataFrame = spark.sql _\r\n",
        "  spark.udf.register(\"cleanseZipCode\", UdfFunction.cleanseZipCode)\r\n",
        "  \"zip code 7689\" should \"returns an empty string; because It is an invalid zip code\" in {\r\n",
        "    val assertValue = \"\"\r\n",
        "    val inputValue= \"7689\"\r\n",
        "    val returnValue = getCleansedZipCode(inputValue)\r\n",
        "    returnValue should be (assertValue)\r\n",
        "  }\r\n",
        "  \"zip code 76869\" should \"returns a valid zipcode\" in {\r\n",
        "    val assertValue = \"76869\"\r\n",
        "    val returnValue = getCleansedZipCode(\"76869\")\r\n",
        "    returnValue should be (assertValue)\r\n",
        "  }\r\n",
        "  \"zip code 76869-8976\" should \"returns a valid zipcode\" in {\r\n",
        "    val assertValue = \"76869-8976\"\r\n",
        "    val returnValue = getCleansedZipCode(\"76869-8976\")\r\n",
        "    returnValue should be (assertValue)\r\n",
        "  }\r\n",
        "  \"empty zip code\" should \"returns an empty string; because It is an invalid zip code\" in {\r\n",
        "   val assertValue = \"\"\r\n",
        "    val returnValue = getCleansedZipCode(\"\")\r\n",
        "    returnValue should be (assertValue)\r\n",
        "  }\r\n",
        "  /**\r\n",
        "   * get cleansed zipcode using udf\r\n",
        "   * @param inputValue\r\n",
        "   * @return\r\n",
        "   */\r\n",
        "  private def getCleansedZipCode(inputValue: String) = sql(s\"select cleanseZipCode('${inputValue}')\").head().getString(0)\r\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "testpool",
              "session_id": "44",
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-25T17:32:51.0694416Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-25T17:32:51.1726555Z",
              "execution_finish_time": "2023-01-25T17:32:56.4927936Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(testpool, 44, 13, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import org.apache.spark.sql.{DataFrame, SparkSession}\nimport org.scalatest._\nimport flatspec._\nimport matchers._\ndefined class UdfFunctionSpec\n"
          ]
        }
      ],
      "execution_count": 83,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "// run test cases using ScalaTest's simple runner.\r\n",
        "import org.scalatest._\r\n",
        "run(new UdfFunctionSpec)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "testpool",
              "session_id": "44",
              "statement_id": 14,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-01-25T17:32:59.069612Z",
              "session_start_time": null,
              "execution_start_time": "2023-01-25T17:32:59.171707Z",
              "execution_finish_time": "2023-01-25T17:33:01.9631968Z",
              "spark_jobs": null
            },
            "text/plain": "StatementMeta(testpool, 44, 14, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mUdfFunctionSpec:\u001b[0m\n\u001b[32mzip code 7689\u001b[0m\n\u001b[32m- should returns an empty string; because It is an invalid zip code\u001b[0m\n\u001b[32mzip code 76869\u001b[0m\n\u001b[32m- should returns a valid zipcode\u001b[0m\n\u001b[32mzip code 76869-8976\u001b[0m\n\u001b[32m- should returns a valid zipcode\u001b[0m\n\u001b[32mempty zip code\u001b[0m\n\u001b[32m- should returns an empty string; because It is an invalid zip code\u001b[0m\nimport org.scalatest._\n"
          ]
        }
      ],
      "execution_count": 84,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "scala"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": "Unit Test cases for the BusinessFunctionsLibrary",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}